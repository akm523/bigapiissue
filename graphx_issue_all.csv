https://api.github.com/repos/amplab/graphx/issues/151,https://api.github.com/repos/amplab/graphx/issues/151/comments,Readability improvements to documentation for mllib-collaborative-filtering.md,Code formatting and header improvements,
https://api.github.com/repos/amplab/graphx/issues/150,https://api.github.com/repos/amplab/graphx/issues/150/comments,Make docs browsable,,
https://api.github.com/repos/amplab/graphx/issues/149,https://api.github.com/repos/amplab/graphx/issues/149/comments,graphx latest version quesion,"it's now surpport semantic graphs and have  data lake? 
",data format
https://api.github.com/repos/amplab/graphx/issues/147,https://api.github.com/repos/amplab/graphx/issues/147/comments,Update README.md,"Hi,

I added section ""Books"" and a link to the Spark GraphX in Action written by Michael S. Malak and Robin East for Manning Publications. We believe this book is a great resource and all members of community will benefit from this information. If you find this inappropriate, please let me know where I can publish it.
",
https://api.github.com/repos/amplab/graphx/issues/146,https://api.github.com/repos/amplab/graphx/issues/146/comments,Graph Constructor needs another type except VertexId?,"Hi,

This might just be me making a fool about myself but I'm using GraphX to run a couple of distributed algorithms on rasters. I essentially just create a graph of the raster, then run a graph algorithm, then I convert it back. So I don't need any metadata except the VertexId (which denotes where in the raster the vertex is). However I can't be able to shake needing another type except the VertexId. I thought about using something like [(VertexId, Null)], and then using the null instance, but I'm guessing it's even cheaper with just a byte. However, is there any way to either skip this another type, or do you have a good reason for having it?

Thanks!
",
https://api.github.com/repos/amplab/graphx/issues/145,https://api.github.com/repos/amplab/graphx/issues/145/comments,How to build project from https://github.com/apache/spark using sbt,"can anyone mention the steps which i need to follow for building spark application also commands to test the scala testcase.referring from https://github.com/apache/spark

I m getting build error 
## Stacktrace

[ERROR] Failed to execute goal on project spark-core_2.10: Could not resolve dependencies for project org.apache.spark:spark-core_2.10:jar:1.1.0-SNAPSHOT: Failed to collect dependencies at org.easymoc
k:easymockclassextension:jar:3.1: Failed to read artifact descriptor for org.easymock:easymockclassextension:jar:3.1: Could not transfer artifact org.easymock:easymockclassextension:pom:3.1 from/to ma
ven-repo (http://repo.maven.apache.org/maven2): Access denied to: http://repo.maven.apache.org/maven2/org/easymock/easymockclassextension/3.1/easymockclassextension-3.1.pom , ReasonPhrase:Forbidden. -

> [Help 1]

Thanx
",app building
https://api.github.com/repos/amplab/graphx/issues/144,https://api.github.com/repos/amplab/graphx/issues/144/comments,Getting eror to run scala testcases from https://github.com/amplab/graphx/blob/master/graphx/src/test/scala/org/apache/spark/graphx/GraphSuite.scala getting error ,"When i m trying to run scala testcases from https://github.com/amplab/graphx/blob/master/graphx/src/test/scala/org/apache/spark/graphx/GraphSuite.scala getting error 
## Stacktrace 

WARNING: -p has been deprecated and will be reused for a different (but still very cool) purpose in ScalaTest 2.0. Please change all uses of -p to -R. 
**\* RUN ABORTED **\* 
  java.lang.ClassNotFoundException: org.apache.spark.graphx.GraphTestSuite 
  at java.net.URLClassLoader$1.run(URLClassLoader.java:366) 
  at java.net.URLClassLoader$1.run(URLClassLoader.java:355) 
  at java.security.AccessController.doPrivileged(Native Method) 
  at java.net.URLClassLoader.findClass(URLClassLoader.java:354) 
  at java.lang.ClassLoader.loadClass(ClassLoader.java:424) 
  at java.lang.ClassLoader.loadClass(ClassLoader.java:357) 
  at org.scalatest.tools.Runner$$anonfun$21.apply(Runner.scala:1470) 
  at org.scalatest.tools.Runner$$anonfun$21.apply(Runner.scala:1469) 
  at scala.collection.TraversableLike$$anonfun$filter$1.apply(TraversableLike.scala:264) 
  at scala.collection.immutable.List.foreach(List.scala:318) 
## In Scala Test IDE: 

Event: 
Run Aborted 

Message: 
Unable to load a Suite class. This could be due to an error in your runpath. Missing class: org.apache.spark.graphx.GraphTestSuite 
Date: 
Thu Jul 17 11:49:57 IST 2014 
Thread: 
Thread-2 
Exception: 
java.lang.ClassNotFoundException 
java.net.URLClassLoader$1.run(URLClassLoader.java:366) java.net.URLClassLoader$1.run(URLClassLoader.java:355) java.security.AccessController.doPrivileged(Native Method) java.net.URLClassLoader.findClass(URLClassLoader.java:354) java.lang.ClassLoader.loadClass(ClassLoader.java:424) java.lang.ClassLoader.loadClass(ClassLoader.java:357) org.scalatest.tools.Runner$$anonfun$21.apply(Runner.scala:1470) org.scalatest.tools.Runner$$anonfun$21.apply(Runner.scala:1469) scala.collection.TraversableLike$$anonfun$filter$1.apply(TraversableLike.scala:264) scala.collection.immutable.List.foreach(List.scala:318) scala.collection.TraversableLike$class.filter(TraversableLike.scala:263) scala.collection.AbstractTraversable.filter(Traversable.scala:105) org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1469) org.scalatest.tools.RunnerJFrame$RunnerThread$$anonfun$run$1.apply(RunnerJFrame.scala:1361) org.scalatest.tools.RunnerJFrame$RunnerThread$$anonfun$run$1.apply(RunnerJFrame.scala:1359) org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1645) org.scalatest.tools.RunnerJFrame$RunnerThread.run(RunnerJFrame.scala:1358) 

Can anyone please giude me . 
",
https://api.github.com/repos/amplab/graphx/issues/143,https://api.github.com/repos/amplab/graphx/issues/143/comments,Wrong PageRank results,"Hi all,

I tried the static PageRank computation on GraphX (in Spark 1.0.0) with the following code:

```
import org.apache.spark._
import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD

object ord extends Ordering[(VertexId, Double)] { def compare(a:(VertexId, Double), b:(VertexId, Double)) = a._2 compare b._2}

val graph = GraphLoader.edgeListFile(sc, ""/lhome/zma/test.txt"")
for (i <- 0 to 30) {
  println(""iter: "" + i)
  val ranks = graph.staticPageRank(i)
  ranks.vertices.top(100)(ord).foreach(println(_))
}
```

The `/lhome/zma/test.txt` contains a simple graph:

```
0 1
1 3
2 3
3 3
```

The PageRank implemenation (  https://github.com/amplab/graphx/blob/master/graphx/src/main/scala/org/apache/spark/graphx/lib/PageRank.scala ) uses this PageRank definition:

```
PR[i] = alpha + (1 - alpha) * inNbrs[i].map(j => oldPR[j] / outDeg[j]).sum
```

However, the results I get are:

```
iter: 0
(0,0.15)
(1,0.15)
(3,0.15)
(2,0.15)
iter: 1
(3,0.5325)
(1,0.27749999999999997)
(0,0.15)
(2,0.15)
iter: 2
(3,0.8384999999999999)
(1,0.27749999999999997)
(0,0.15)
(2,0.15)
iter: 3
(3,0.862725)
(1,0.27749999999999997)
(0,0.15)
(2,0.15)
...
```

The results with iterNum as 0 and 1 are correct. However, for ""iter: 2"":

The PageRank value for 3 should be:

```
0.15 + 0.85 * (0.27749999999999997 + 0.15 + 0.5325)
= 0.966
```

while the result is `(3,0.8384999999999999)`. It seems the PageRank of vertex 2 is not passed to the PageRank of vertex 3 (`0.8384999999999999 == 0.15 + 0.85 * (0.27749999999999997 + 0.5325)`).

I noticed that the Pregel implementation (https://github.com/amplab/graphx/blob/master/graphx/src/main/scala/org/apache/spark/graphx/Pregel.scala) only sends messages from vertices changed in last superstep. I can understand this performance optimization for less messages. However, is this PageRank implementation on top of this model wrong? Will passing the delta out from changed vertices be more suitable for implementation on this ""Pregel"" model in GraphX?

Please correct me if I am wrong at understanding some parts. I will appreciate it if additional information or pointers to them are provided.
",
https://api.github.com/repos/amplab/graphx/issues/142,https://api.github.com/repos/amplab/graphx/issues/142/comments,how to install GraphX please some one help i need it very badly.,"i set up hadoop cluster a long back.i can see all the folders that are given in amplab/graphx main page.but how to install graphx.what files need to be modified.please someone help please i need guidance very badly
",usability
https://api.github.com/repos/amplab/graphx/issues/141,https://api.github.com/repos/amplab/graphx/issues/141/comments,initial version of LPA,"a straightforward implementation of LPA to detect network communities in graphs using the Pregel framework.
",
https://api.github.com/repos/amplab/graphx/issues/140,https://api.github.com/repos/amplab/graphx/issues/140/comments,Function to remove vertex/edge,"Add functions to remove simple vertex or edge.
",
https://api.github.com/repos/amplab/graphx/issues/139,https://api.github.com/repos/amplab/graphx/issues/139/comments,"There are some issues in article ""Launch a benchmarking cluster"" ","```
I want to run pagerank on Graphx, following the instructions(https://github.com/amplab/graphx/wiki/Launch-a-benchmarking-cluster), I encountered some problems.
First, the running command(~/graphx/run-example org.apache.spark.graph.Analytics spark://$MASTERS:7077 pagerank hdfs://$MASTERS:9000/soc-LiveJournal1.txt --numIter=20 --numEPart=128) is wrong, I changed it to ""./bin/run-example org.apache.spark.graphx.lib.Analytics spark://XXX:7077 pagerank hdfs://XXX:8020/soc-LiveJournal1.txt"". The parameter ""--numIter"" can not be found in running pagerank, I read the source code and find it is used in cc benchmark.
```

   when I run the command above, spark throw warnings and errors:
14/04/21 10:24:59 WARN scheduler.TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
……
Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Spark cluster looks down

   What I am sure is spark UI is ok, and other benchmarks can run rightly.

   What I expect is, if you can give some hint in deploying Graphx on standlone cluster? 
Thanks very very much, cause I have been blocked on this for 1 week. :)
",job running
https://api.github.com/repos/amplab/graphx/issues/138,https://api.github.com/repos/amplab/graphx/issues/138/comments,[Question] Which graphx version to compare to?,"We are comparing performance on some of the example applications in Analytics.scala.
[Results](http://arxiv.org/pdf/1402.2394v1.pdf) show GraphX pagerank performs within a factor of 2-3 of Graphlab. I haven't yet been able to get near this performance.

configurations:
- twitter 1.4B edge
- 16 nodes
- branch master
- command: `bin/spark-class -Dspark.executor.memory=52g org.apache.spark.graphx.lib.Analytics <master> pagerank <graph> --tol=0.01 --numEPart=16`

Do you have a pointer to which branch and what methodology I should use to replicate these results?
",
https://api.github.com/repos/amplab/graphx/issues/137,https://api.github.com/repos/amplab/graphx/issues/137/comments,Unify GraphImpl RDDs + other graph load optimizations,"This is work in progress. The PR also includes hotfixes apache/spark#367 and apache/spark#368. The main change is in 3c7a6bc6c6c5fc2b6ae85d7d757135621c38318b.

This commit makes the following changes:
1. _Unify RDDs to avoid zipPartitions._ A graph used to be four RDDs: vertices, edges, routing table, and triplet view. This commit merges them down to two: vertices (with routing table), and edges (with replicated vertices).
2. _Avoid duplicate shuffle in graph building._ We used to do two shuffles when building a graph: one to extract routing information from the edges and move it to the vertices, and another to find nonexistent vertices referred to by edges. With this commit, the latter is done as a side effect of the former.
3. _Avoid no-op shuffle when joins are fully eliminated._ This is a side effect of unifying the edges and the triplet view.
4. _Join elimination for mapTriplets._
5. _Ship only the needed vertex attributes when upgrading the triplet view._ If the triplet view already contains source attributes, and we now need both attributes, only ship destination attributes rather than re-shipping both. This is done in `ReplicatedVertexView#upgrade`.
",IO
https://api.github.com/repos/amplab/graphx/issues/136,https://api.github.com/repos/amplab/graphx/issues/136/comments,Experimental support for mutable RDDs in delta updates,"This breaks correctness in general, but is OK on our benchmarks.

I benchmarked it for connected components on uk-union, and it provides a 57% speedup. I ran 10 trials of 20 iterations each on 16 m2.4xlarge machines, coalescing the input to 64 partitions. Original runtime was 870 +/- 31 s, and with this PR it was reduced to 369 +/- 6 s.
",performance
https://api.github.com/repos/amplab/graphx/issues/133,https://api.github.com/repos/amplab/graphx/issues/133/comments,A previously working version of Kcore,"This version works but is out of date to the current repo. I will update this later when I have time to rebase it on top of the current master, but this should serve as a mostly complete reference for now.
",
https://api.github.com/repos/amplab/graphx/issues/132,https://api.github.com/repos/amplab/graphx/issues/132/comments,Merge Spark master in preparation for release,"I encountered a mysterious bug documented and fixed in 99cf724f3e5cb95008e958f25f01ded7d5c9083d.
",
https://api.github.com/repos/amplab/graphx/issues/131,https://api.github.com/repos/amplab/graphx/issues/131/comments,Make sure there is a license at the top of every file,"We need to make sure our code is properly licensed before announcing a release.
",
https://api.github.com/repos/amplab/graphx/issues/130,https://api.github.com/repos/amplab/graphx/issues/130/comments,Added graph.algorithms._ as a default import when launching the graphx shell,,
https://api.github.com/repos/amplab/graphx/issues/129,https://api.github.com/repos/amplab/graphx/issues/129/comments,Added undirected version of Pregel.,,
https://api.github.com/repos/amplab/graphx/issues/128,https://api.github.com/repos/amplab/graphx/issues/128/comments,"Fix failing ""sbt/sbt publish-local"" by adding a no-argument PrimitiveKeyOpenHashMap constructor","Changing org.apache.spark.util.collection.PrimitiveKeyOpenHashMap to have a real no-argument constructor, instead of a one-argument constructor with a default value. The lack of a real no-argument constructor was causing ""sbt/sbt publish-local"" to fail thusly:

```
[error] /pod/home/anovak/build/graphx/core/src/main/scala/org/apache/spark/storage/ShuffleBlockManager.scala:172: not enough arguments for constructor PrimitiveKeyOpenHashMap: (initialCapacity: Int)(implicit evidence$3: ClassManifest[Int], implicit evidence$4: ClassManifest[Int])org.apache.spark.util.collection.PrimitiveKeyOpenHashMap[Int,Int]
[error]     private val mapIdToIndex = new PrimitiveKeyOpenHashMap[Int, Int]()
[error]                                ^
[info] No documentation generated with unsucessful compiler run
[error] one error found
[error] (core/compile:doc) Scaladoc generation failed
[error] Total time: 67 s, completed Jan 6, 2014 2:20:51 PM
```

In theory a no-argument constructor ought not to differ from one with a single argument that has a default value, but in practice there seems to be an issue.
",
https://api.github.com/repos/amplab/graphx/issues/127,https://api.github.com/repos/amplab/graphx/issues/127/comments,Adding mapEdges and mapTriplets by Partition,"These functions were added to support random number generation while transforming edge attributes in a deterministic fashion.  

To support these changes consistently, I pass the partition Id along with the EdgePartition in EdgeRDD operations.
",job
https://api.github.com/repos/amplab/graphx/issues/126,https://api.github.com/repos/amplab/graphx/issues/126/comments,Fixing Persist Behavior,"The persist behavior of the current Vertex and Edge RDDs persist the pervious RDD (recursively?) instead of the current RDD.  This is addressed by instead calling the persist on the parent RDD class.
",parallelism
https://api.github.com/repos/amplab/graphx/issues/125,https://api.github.com/repos/amplab/graphx/issues/125/comments,Update VTableReplicated.scala,"VertexAttributeBlock will throw NotSerializableException in graphx-shell
",
https://api.github.com/repos/amplab/graphx/issues/124,https://api.github.com/repos/amplab/graphx/issues/124/comments,refactor and bug fix,,
